This page is for Neural Machine Translation (NMT) Research-related.
## codes
* [OpenNMT](http://opennmt.net/) 
 * Havard NLP and Systran
 * by Torch

* [NMT by Thang Luong](https://github.com/lmthang/nmt.matlab)
 * Thang Luong(Stanford)
 * Matlab

* [Seq2Seq Tensorflow](https://www.tensorflow.org/tutorials/seq2seq/)
 * Tensorflow
 * Python

* [nmtkit](https://github.com/odashi/nmtkit)
 * C++
 * based on DyNet

* [lamtram: A toolkit for language and translation modeling using neural networks](https://github.com/neubig/lamtram)
 * Graham Neubig

* [nematus](https://github.com/rsennrich/nematus)
 * senrich
 * based on the dl4mt-tutorial by Kyunghyun Cho
 * python theano

* [ByteNet](https://github.com/buriburisuri/ByteNet/blob/master/README.md)
 * ByteNet - Fast Neural Machine Translation
 * A tensorflow implementation of French-to-English machine translation using DeepMind's ByteNet from the paper Nal et al's Neural Machine Translation in Linear Time. 

* [Seq2Seq Translation using PyTorch](https://github.com/spro/practical-pytorch/blob/master/seq2seq-translation/seq2seq-translation.ipynb)
 * ipython notebook
 * Practical PyTorch: Translation with a Sequence to Sequence Network and Attention

## Tutorial
* [MTMA16-Neural Machine Translation](http://statmt.org/mtma16/uploads/mtma16-neural.pdf)

## Modeling 
* [Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation](http://arxiv.org/abs/1406.1078)
 * Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, Yoshua Bengio
* [Effective Approaches to Attention-based Neural Machine Translation](https://arxiv.org/abs/1508.04025)
 * Minh-Thang Luong, Hieu Pham, Christopher D. Manning

## Vocabulary problem (OOV)
* [Neural Machine Translation of Rare Words with Subword Units](https://arxiv.org/abs/1508.07909)
 * Rico Sennrich, Barry Haddow, Alexandra Birch

## Improving Model size & speed
* NMT Pruning : [Compression of Neural Machine Translation Models via Pruning](https://arxiv.org/abs/1606.09274)
 * Downsizing model size by using NN Pruning
* Neural Network Pruning : [Learning both Weights and Connections for Efficient Neural Networks](https://arxiv.org/abs/1506.02626)
 * approach from this paper is used upper(NMT Pruning)

* [NMT-Tips](https://github.com/neubig/nmt-tips) 
 * There is tips for speeding up and improving quality on NMT.

## MT Workshop
* [WAT](http://orchid.kuee.kyoto-u.ac.jp/WAT/)
 * Workshop for Asian Translation

## my slides
* [GNMT로 알아보는 신경망 기반 기계번역, Description for Neural Machine Translation based on GNMT](http://www.slideshare.net/ByeongilKo/gnmt-69817390)
